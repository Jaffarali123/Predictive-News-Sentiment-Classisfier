# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/110gXT__eEfCvhMjBBPaSP3KNT9EaGGBM
"""

import numpy as np
import pandas as pd
import nltk
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt

# Download required NLTK data
nltk.download('vader_lexicon')
from nltk.sentiment import SentimentIntensityAnalyzer

# Load and preprocess data
def preprocess_text(text):
    # Remove any unwanted characters or perform additional cleaning if needed
    return text.lower()

# Sentiment Analysis Model using Naive Bayes
def build_model():
    # Create a pipeline for text preprocessing and classification
    model = make_pipeline(CountVectorizer(), MultinomialNB())
    return model

# Perform sentiment classification
def analyze_sentiment(news_data):
    # Initialize sentiment intensity analyzer from NLTK
    sia = SentimentIntensityAnalyzer()

    sentiments = []
    for article in news_data:
        score = sia.polarity_scores(article)
        if score['compound'] > 0.05:
            sentiments.append('positive')
        elif score['compound'] < -0.05:
            sentiments.append('negative')
        else:
            sentiments.append('neutral')
    return sentiments

# Function to visualize sentiment distribution
def visualize_sentiment_distribution(sentiments):
    unique, counts = np.unique(sentiments, return_counts=True)
    plt.pie(counts, labels=unique, autopct='%1.1f%%', startangle=90, colors=['green', 'red', 'blue'])
    plt.title('Sentiment Distribution')
    plt.show()

# Main function to run the sentiment analysis
def main(input_data):
    # Step 1: Preprocess the input data
    news_data = [preprocess_text(article) for article in input_data]

    # Step 2: Analyze the sentiment of each article
    sentiments = analyze_sentiment(news_data)

    # Step 3: Display results
    for i, sentiment in enumerate(sentiments):
        print(f"Article {i+1}: {sentiment}")

    # Step 4: Visualize sentiment distribution
    visualize_sentiment_distribution(sentiments)

if __name__ == "__main__":
    # Example input data: Replace these with real news articles or text input
    input_data = [
        "The economy is doing great, with stock markets reaching new highs.",
        "There are rising concerns about the current state of climate change.",
        "The political landscape remains neutral with no significant changes."
    ]

    main(input_data)

